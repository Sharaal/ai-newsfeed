---
layout: post
language: de
title: >-
  Google-Forscher präsentieren ScreenAI: KI versteht und interagiert mit
  Bildschirminhalten
aigenerated: true
categories:
  - name: ai
    relevance: 9
    reasoning: >-
      ScreenAI ist ein bahnbrechendes KI-Modell, das Vision-Language-Technologie
      nutzt und neue Maßstäbe in der multimodalen KI-Entwicklung setzt -
      hochrelevant für alle AI-Interessierten.
  - name: programming
    relevance: 7
    reasoning: >-
      Die Technologie hat direkten Bezug zur Softwareentwicklung durch
      automatisierte UI-Tests und die Möglichkeit, mit Benutzeroberflächen zu
      interagieren - wichtig für Entwickler und Tester.
  - name: work
    relevance: 8
    reasoning: >-
      ScreenAI könnte Arbeitsabläufe grundlegend verändern, von der
      Barrierefreiheit bis zur Automatisierung von UI-Interaktionen - sehr
      relevant für die moderne Arbeitswelt.
  - name: security
    relevance: 5
    reasoning: >-
      Obwohl nicht explizit erwähnt, birgt eine KI, die Bildschirminhalte
      analysiert und mit UIs interagiert, potenzielle Sicherheitsimplikationen -
      mäßig relevant für Sicherheitsexperten.
  - name: data protection
    relevance: 6
    reasoning: >-
      Eine KI, die Bildschirminhalte erfasst und analysiert, wirft Fragen zum
      Datenschutz auf, auch wenn dies im Artikel nicht thematisiert wird -
      relevant für Datenschutzbeauftragte.
---

Google hat mit ScreenAI ein neues KI-Modell vorgestellt, das die Interaktion mit Bildschirminhalten revolutionieren könnte. ScreenAI kombiniert visuelle und sprachliche Verarbeitung, um Benutzeroberflächen (UIs) und Infografiken zu verstehen, zu analysieren und mit ihnen zu interagieren. Die Technologie ermöglicht es, UI-Elemente zu identifizieren, ihre Funktion zu erklären und sogar Anweisungen wie "Klicke auf den Suchbutton" auszuführen. Besonders beeindruckend ist die Fähigkeit, den Inhalt eines Bildschirms zusammenzufassen oder Fragen zu spezifischen Elementen zu beantworten.

<!--more-->

Das Modell basiert auf Googles fortschrittlicher Vision-Language-Technologie und nutzt synthetische Trainingsdaten, die mit dem PaLM 2-S Modell generiert wurden. ScreenAI wurde in verschiedenen Benchmarks getestet und übertrifft dabei viele bestehende Modelle, auch solche mit größerer Parameteranzahl. Die potenziellen Anwendungsbereiche sind vielfältig: von der Unterstützung sehbehinderter Nutzer durch detaillierte Beschreibungen von Interfaces bis hin zu automatisierten Tests von Benutzeroberflächen. Auch Sprachassistenten könnten durch ScreenAI in der Lage sein, besser mit dargestellten Inhalten zu interagieren.

Trotz der beeindruckenden Fortschritte betonen die Forscher, dass ScreenAI noch nicht vollständig ausgereift ist. Insbesondere die praktische Umsetzung der generierten Aktionen steht noch aus. Dennoch zeigt die Entwicklung, wie KI zunehmend in der Lage ist, komplexe visuelle und sprachliche Aufgaben zu bewältigen und so den Alltag der Nutzer zu erleichtern.

### Quellen
- [Google Research Blog](https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/)
- [Golem.de](https://www.golem.de/news/screenai-googles-ki-versteht-user-interfaces-und-bedient-sie-2403-183437.html)
- [The Decoder](https://the-decoder.de/googles-screenai-navigiert-zuverlaessig-ueber-smartphone-oberflaechen/)
